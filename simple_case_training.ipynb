{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ayeghiazaryan/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_modules import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a toy dataset, where output sequence is the same as input\n",
    "N_ = 1000  #dataset size\n",
    "n_seq = 15  #sizes of sequences\n",
    "max_val = 10  #number of distinct 'characters', input and output will be numbers from 0 to max_val\n",
    "inp_data = np.random.randint(low=0, high=max_val, size = (N_,n_seq))  #random sequences as inputs\n",
    "out_data = np.concatenate([np.full([N_, 1], np.max(inp_data)+1), inp_data], axis = 1)  #outputs should be shifted by 1 character to the right, \n",
    "                                                                                       #insert a dummy character in the beginning\n",
    "\n",
    "data = (inp_data, out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for decoder output placeholder feeding\n",
    "def get_labels(dec_inp_batch):\n",
    "    '''decoder output is the same as the decoder input shifted by one position.\n",
    "    The input argument should be given already the shifted sequence, i.e. the output ground truth'''\n",
    "    lbls = np.zeros([*dec_inp_batch.shape, max_val+1])\n",
    "    for i in range(lbls.shape[0]):\n",
    "        for j in range(lbls.shape[1]):\n",
    "            lbls[i,j,dec_inp_batch[i,j]] = 1\n",
    "    return lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input and output placeholders\n",
    "enc_inp_seq = tf.placeholder(shape=(None, n_seq), dtype=tf.int32, name='enc_inp_plhd') \n",
    "dec_inp_seq = tf.placeholder(shape=(None, n_seq), dtype=tf.int32, name='dec_inp_plhd') \n",
    "out_lbls = tf.placeholder(shape=(None, n_seq, max_val+1), dtype=tf.int32, name='out_plhd') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 50 #size of the embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the embeddings\n",
    "inp_embs = WordEmbeddings(d_model=d_model, d_vocab=max_val, name='inp_embs')\n",
    "out_embs = WordEmbeddings(d_model=d_model, d_vocab=max_val+1, name='out_embs')\n",
    "\n",
    "#declare the tensors to be fed to model as encoder and decoder inputs\n",
    "tsf_enc_inp = inp_embs(enc_inp_seq)\n",
    "tsf_dec_inp = out_embs(dec_inp_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask for keeping the decoder from having access to it's own subsequent entries\n",
    "mask = subsequent_mask(n_seq)\n",
    "mask = tf.expand_dims(tf.constant(mask), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholder for decoder mask\n",
    "dec_mask = tf.placeholder_with_default(input=mask, shape = mask.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting logger level to 5 to skip the debugging messages\n",
    "logger.setLevel(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#Defining the model\n",
    "model = TransformerModel(d_inp_vocab=max_val, d_out_vocab=max_val+1, d_model=d_model, n_blocks=1, n_heads=5, d_ff=100, dropout=0)\n",
    "out = model(tsf_enc_inp, tsf_dec_inp, tgt_mask=dec_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the loss and the train step\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=out_lbls, logits=out, dim=-1))\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=0.003, name = 'adam').minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining an op to track the accuracy\n",
    "correct_preds = tf.equal(tf.argmax(out, axis=-1), tf.argmax(out_lbls, axis=-1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_preds, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(device_count = {'GPU': 0}) #train on cpu\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, loss value: 4.581195831298828, accuracy: 0.07999999821186066\n",
      "Step 50, loss value: 2.193573474884033, accuracy: 0.18222221732139587\n",
      "Step 0, loss value: 1.9281103610992432, accuracy: 0.31111112236976624\n",
      "Step 50, loss value: 0.16025954484939575, accuracy: 0.9599999785423279\n",
      "Step 0, loss value: 0.03066381625831127, accuracy: 1.0\n",
      "Step 50, loss value: 0.0037801959551870823, accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size=15\n",
    "for epoch in range(n_epochs):\n",
    "    batch_iter = gen_batch(data, batch_size=15)\n",
    "    for i, next_batch in enumerate(batch_iter):\n",
    "        if len(next_batch[0]) != 0:\n",
    "            loss_i, _, acc_i = sess.run([loss, train_step, accuracy], feed_dict={enc_inp_seq: next_batch[0], dec_inp_seq:next_batch[1][:,:-1], out_lbls: get_labels(next_batch[1][:,1:])})\n",
    "            if i % 50 == 0:\n",
    "                print ('Step {}, loss value: {}, accuracy: {}'.format(i,loss_i, acc_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for inference. Greedy\n",
    "def predict(enc_inp):\n",
    "    N_seq = 15\n",
    "    dec_inp = np.zeros([1,N_seq])\n",
    "    dec_inp[:,0]=10 #first decoder input should be the dummy character, the rest will be masked by _mask\n",
    "    \n",
    "    output = np.zeros(N_seq).astype(np.int8) #an array for the final output\n",
    "    \n",
    "    for i in range(N_seq):\n",
    "        _mask = np.zeros([1,1,N_seq,N_seq])  \n",
    "        _mask[:,:,:,:i+1] = 1 #keep access only to first i elements of the sequence, mask the rest\n",
    "        pred_i = sess.run(tf.argmax(tf.nn.softmax(out, axis=-1), axis=-1), feed_dict={enc_inp_seq: enc_inp, dec_inp_seq:dec_inp, dec_mask:_mask}) #prediction at the i-th iteration\n",
    "        dec_inp[:,i] = pred_i[0][i] #next decoder input should include the last predicition\n",
    "        output[i] = pred_i[0][i] #i-th element of the prediction\n",
    "        print ('At iteration {}, sequence prediction: {}, instance prediction: {}'.format(i, pred_i[0], output[i]))\n",
    "    print ('\\n')\n",
    "    print ('Encoder input: {}'.format(enc_inp[0]))\n",
    "    print ('Decoder output: {}'.format(output))\n",
    "    print ('Prediction was correct: {}'.format(np.all(output == enc_inp[0])))\n",
    "    return output.astype(np.int8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 7, 0, 8, 1, 2, 2, 3, 0, 2, 9, 7, 1, 6, 2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_inp = np.random.randint(low=0, high=10, size=(1,15)) #some random sequence for input\n",
    "rand_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 0, sequence prediction: [7 7 2 8 7 2 2 7 0 2 9 7 1 7 2], instance prediction: 7\n",
      "At iteration 1, sequence prediction: [7 7 0 8 1 2 2 3 0 2 9 7 6 2 2], instance prediction: 7\n",
      "At iteration 2, sequence prediction: [2 7 0 8 1 2 2 3 0 2 9 7 2 2 2], instance prediction: 0\n",
      "At iteration 3, sequence prediction: [2 2 0 8 1 2 2 3 0 2 9 7 6 2 2], instance prediction: 8\n",
      "At iteration 4, sequence prediction: [2 2 0 8 1 2 2 3 0 2 9 7 1 6 2], instance prediction: 1\n",
      "At iteration 5, sequence prediction: [2 2 2 8 1 2 2 3 0 2 9 7 1 6 2], instance prediction: 2\n",
      "At iteration 6, sequence prediction: [2 2 2 8 1 2 2 3 0 2 9 7 1 6 2], instance prediction: 2\n",
      "At iteration 7, sequence prediction: [2 2 2 8 1 2 2 3 0 2 9 7 1 6 2], instance prediction: 3\n",
      "At iteration 8, sequence prediction: [7 2 0 8 1 2 2 3 0 2 9 7 1 6 2], instance prediction: 0\n",
      "At iteration 9, sequence prediction: [6 2 0 8 1 2 2 3 0 2 9 7 1 6 2], instance prediction: 2\n",
      "At iteration 10, sequence prediction: [7 2 0 8 1 2 2 3 0 2 9 7 1 6 2], instance prediction: 9\n",
      "At iteration 11, sequence prediction: [9 2 0 8 1 2 2 3 0 2 9 7 1 6 2], instance prediction: 7\n",
      "At iteration 12, sequence prediction: [7 2 0 8 1 2 2 3 0 2 9 7 1 6 2], instance prediction: 1\n",
      "At iteration 13, sequence prediction: [9 2 0 8 1 2 2 3 0 2 9 7 1 6 2], instance prediction: 6\n",
      "At iteration 14, sequence prediction: [7 2 0 8 1 2 2 3 0 2 9 7 1 6 2], instance prediction: 2\n",
      "\n",
      "\n",
      "Encoder input: [7 7 0 8 1 2 2 3 0 2 9 7 1 6 2]\n",
      "Decoder output: [7 7 0 8 1 2 2 3 0 2 9 7 1 6 2]\n",
      "Prediction was correct: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 7, 0, 8, 1, 2, 2, 3, 0, 2, 9, 7, 1, 6, 2], dtype=int8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(rand_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
